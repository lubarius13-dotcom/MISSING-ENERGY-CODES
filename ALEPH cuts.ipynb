{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f85db18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "from math import sqrt\n",
    "from scipy.special import erfc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53dd15c8",
   "metadata": {},
   "outputs": [],
   "source": [
    " # ------------------------\n",
    "# Utilities\n",
    "# ------------------------\n",
    "\n",
    "VISIBLE_PDGS = np.array([\n",
    "    211, -211,    # pi±\n",
    "    111,          # pi0\n",
    "    321, -321,    # K±\n",
    "    2212, -2212,  # p, p̅\n",
    "    2112, -2112,  # n, n̅\n",
    "    130,          # K_L0\n",
    "    22,           # γ\n",
    "    11, -11,      # e±\n",
    "    13, -13       # μ±\n",
    "], dtype=int)\n",
    "\n",
    "CHARGED_PDGS = np.array([\n",
    "    211, -211,\n",
    "    321, -321,\n",
    "    2212, -2212,\n",
    "    11, -11,\n",
    "    13, -13\n",
    "], dtype=int)\n",
    "\n",
    "LEPTON_PDGS = {11, -11, 13, -13}\n",
    "\n",
    "def compute_thrust_event_aleph_like(px, py, pz, n_iter=10, n_random=5):\n",
    "    \"\"\"\n",
    "    ALEPH-like thrust finder:\n",
    "    - Uses |p|, |pz|, and a few random seeds\n",
    "    - Less 'perfect' than all-seeds, closer to ALEPH reconstruction\n",
    "    \"\"\"\n",
    "    p = np.column_stack((px, py, pz))\n",
    "    p_mag = np.linalg.norm(p, axis=1)\n",
    "    total_mag = np.sum(p_mag)\n",
    "\n",
    "    if total_mag == 0:\n",
    "        return 0.0, 1.0, np.array([0., 0., 1.])\n",
    "\n",
    "    seeds = []\n",
    "\n",
    "    # 1. Seed from largest |p|\n",
    "    idx_maxp = np.argmax(p_mag)\n",
    "    seeds.append(p[idx_maxp] / p_mag[idx_maxp])\n",
    "\n",
    "    # 2. Seed from largest |pz|\n",
    "    idx_maxpz = np.argmax(np.abs(p[:, 2]))\n",
    "    if p_mag[idx_maxpz] > 0:\n",
    "        seeds.append(p[idx_maxpz] / p_mag[idx_maxpz])\n",
    "\n",
    "    # 3. Random seeds from visible particles\n",
    "    n_available = len(p)\n",
    "    if n_available > 0:\n",
    "        n_rand = min(n_random, n_available)\n",
    "        rand_idx = np.random.choice(n_available, n_rand, replace=False)\n",
    "        for i in rand_idx:\n",
    "            if p_mag[i] > 0:\n",
    "                seeds.append(p[i] / p_mag[i])\n",
    "\n",
    "    best_thrust = -1.0\n",
    "    best_axis = np.array([0., 0., 1.])\n",
    "\n",
    "    # Iterate thrust maximization\n",
    "    for axis in seeds:\n",
    "        prev_thrust = -1.0\n",
    "        for _ in range(n_iter):\n",
    "            dots = p @ axis\n",
    "            signs = np.sign(dots)\n",
    "            new_axis = np.sum(signs[:, None] * p, axis=0)\n",
    "            norm = np.linalg.norm(new_axis)\n",
    "            if norm == 0:\n",
    "                break\n",
    "            axis = new_axis / norm\n",
    "            thrust_val = np.sum(np.abs(p @ axis)) / total_mag\n",
    "            if abs(thrust_val - prev_thrust) < 1e-6:\n",
    "                break\n",
    "            prev_thrust = thrust_val\n",
    "\n",
    "        # Final thrust\n",
    "        thrust_val = np.sum(np.abs(p @ axis)) / total_mag\n",
    "        if thrust_val > best_thrust:\n",
    "            best_thrust = thrust_val\n",
    "            best_axis = axis\n",
    "\n",
    "    cos_theta_thrust = abs(best_axis[2])\n",
    "    return best_thrust, cos_theta_thrust, best_axis\n",
    "\n",
    "\n",
    "def compute_thrust_with_angle2(px, py, pz, n_iter=5, tol=1e-3):\n",
    "    \"\"\"\n",
    "    Iterative thrust with |p|-seed, early convergence, and sign-robust stopping.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    thrust_val : float\n",
    "    cos_theta_thrust : float\n",
    "    axis : np.ndarray shape (3,)\n",
    "    \"\"\"\n",
    "    p = np.column_stack((px, py, pz)).astype(float)\n",
    "    p_mag = np.linalg.norm(p, axis=1)\n",
    "    denom = p_mag.sum()\n",
    "    if denom == 0.0:\n",
    "        return 0.0, 1.0, np.array([0.0, 0.0, 1.0])\n",
    "\n",
    "    # Seed with direction of largest |p|\n",
    "    lead = np.argmax(p_mag)\n",
    "    axis = p[lead]\n",
    "    norm = np.linalg.norm(axis)\n",
    "    axis = axis / norm if norm > 0.0 else np.array([0.0, 0.0, 1.0])\n",
    "\n",
    "    for _ in range(n_iter):\n",
    "        # s_i = sign(p_i · n); resolve exact zeros deterministically as +1\n",
    "        proj = p @ axis\n",
    "        signs = np.sign(proj)\n",
    "        signs[signs == 0.0] = 1.0\n",
    "\n",
    "        new_axis = (signs[:, None] * p).sum(axis=0)\n",
    "        new_norm = np.linalg.norm(new_axis)\n",
    "        if new_norm == 0.0:\n",
    "            break\n",
    "        new_axis /= new_norm\n",
    "\n",
    "        # Convergence up to a global sign: stop when n and new_n are aligned\n",
    "        if 1.0 - abs(np.dot(axis, new_axis)) < tol:\n",
    "            axis = new_axis\n",
    "            break\n",
    "\n",
    "        axis = new_axis\n",
    "\n",
    "    thrust_val = np.sum(np.abs(p @ axis)) / denom\n",
    "    cos_theta_thrust = abs(axis[2])\n",
    "    return thrust_val, cos_theta_thrust, axis\n",
    "\n",
    "\n",
    "def has_identified_lepton(pdg_h, E_h, p_h, p_min=2.0):\n",
    "    for pdg, E, p in zip(pdg_h, E_h, p_h):\n",
    "        if abs(pdg) in LEPTON_PDGS and p > p_min:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "854e2113",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _vt_unit(px, py, eps=1e-12):\n",
    "    pT = np.hypot(px, py)\n",
    "    vx = np.divide(px, pT, out=np.zeros_like(px, dtype=float), where=pT>eps)\n",
    "    vy = np.divide(py, pT, out=np.zeros_like(py, dtype=float), where=pT>eps)\n",
    "    return vx, vy, pT\n",
    "\n",
    "def _sigma_d0_um(px, py, pz, a_um=25.0, b_um=95.0):\n",
    "    \"\"\"ALEPH-like σ(d0): sqrt(25^2 + (95/p)^2) in microns.\"\"\"\n",
    "    p = np.sqrt(px**2 + py**2 + pz**2) + 1e-12\n",
    "    return np.sqrt(a_um**2 + (b_um/p)**2)\n",
    "\n",
    "def _erfc_half_from_absS(S_abs):\n",
    "    \"\"\"\n",
    "    Return 0.5*erfc(S/sqrt(2)) for array-like S_abs using\n",
    "    Abramowitz–Stegun 7.1.26 (no SciPy/np.erfc needed).\n",
    "    \"\"\"\n",
    "    S_abs = np.asarray(S_abs, float)\n",
    "    y = S_abs / np.sqrt(2.0)\n",
    "    # A&S constants\n",
    "    p  = 0.3275911\n",
    "    a1 = 0.254829592; a2 = -0.284496736; a3 = 1.421413741\n",
    "    a4 = -1.453152027; a5 =  1.061405429\n",
    "    t = 1.0/(1.0 + p*y)\n",
    "    poly = (((((a5*t + a4)*t + a3)*t + a2)*t + a1)*t)\n",
    "    erfc_y = poly * np.exp(-y*y)\n",
    "    return 0.5 * erfc_y\n",
    "\n",
    "def track_pv_probability_simple(x_mm, y_mm, px, py, pz,\n",
    "                                a_um=25.0, b_um=95.0,\n",
    "                                sigma_scale=1.0, S_cap=5.0):\n",
    "    \"\"\"\n",
    "    PV probability using transverse d0 only.\n",
    "    x,y in mm; p in GeV; σ(d0) in μm. No SciPy needed.\n",
    "    \"\"\"\n",
    "    p = sqrt(px*px + py*py + pz*pz)\n",
    "    if p <= 0.0:\n",
    "        return 1.0\n",
    "    pT = sqrt(px*px + py*py)\n",
    "    if pT <= 0.0:\n",
    "        return 1.0\n",
    "\n",
    "    vx, vy = px/pT, py/pT\n",
    "    d0_mm = abs(x_mm*vy - y_mm*vx)\n",
    "\n",
    "    # σ(d0) in μm, with your global scale\n",
    "    sig = sqrt((a_um*sigma_scale)**2 + (b_um*sigma_scale/p)**2)\n",
    "    S   = (1e3 * d0_mm) / max(sig, 1e-3)   # mm → μm\n",
    "    S   = min(abs(S), S_cap)               # cap |S| to avoid one crazy track dominating\n",
    "\n",
    "    # one-sided PV prob: 0.5*erfc(S/√2) via Abramowitz–Stegun 7.1.26\n",
    "    y = S / sqrt(2.0)\n",
    "    pc, a1,a2,a3,a4,a5 = 0.3275911, 0.254829592, -0.284496736, 1.421413741, -1.453152027, 1.061405429\n",
    "    t = 1.0/(1.0 + pc*y)\n",
    "    erfc_y = (((((a5*t + a4)*t + a3)*t + a2)*t + a1)*t) * np.exp(-y*y)\n",
    "    return float(0.5 * erfc_y)\n",
    "\n",
    "def hemisphere_btag_aleph_simple(\n",
    "    x_mm, y_mm, px, py, pz, pdg,\n",
    "    alpha_hemi_cut=0.01, min_tracks=6, pmin=0.5,\n",
    "    a_um=25.0, b_um=95.0, ip_cap_mm=4.0,\n",
    "    sigma_scale=1.0, S_cap=5.0, use_topk=2\n",
    "):\n",
    "    \"\"\"\n",
    "    Tag a PRESELECTED hemisphere (you already masked it).\n",
    "    Good tracks: |PDG| in CHARGED_PDGS and p > pmin.\n",
    "    Product of the K most displaced tracks (smallest PV probs).\n",
    "    \"\"\"\n",
    "    x = np.asarray(x_mm, float); y = np.asarray(y_mm, float)\n",
    "    px = np.asarray(px, float);  py = np.asarray(py, float);  pz = np.asarray(pz, float)\n",
    "    pdg = np.asarray(pdg)\n",
    "\n",
    "    p = np.sqrt(px**2 + py**2 + pz**2)\n",
    "    good = (np.isin(np.abs(pdg), CHARGED_PDGS) & (p > pmin))\n",
    "\n",
    "    # IP sanity: drop huge-d0 tracks\n",
    "    vx, vy, _ = _vt_unit(px, py)\n",
    "    d0_mm = np.abs(x*vy - y*vx)\n",
    "    good &= (d0_mm < ip_cap_mm)\n",
    "\n",
    "    idx = np.flatnonzero(good)\n",
    "    n_good = idx.size\n",
    "    if n_good < min_tracks:\n",
    "        return False, 1.0, int(n_good), []\n",
    "\n",
    "    # per-track PV probs\n",
    "    probs = np.array([\n",
    "        track_pv_probability_simple(x[i], y[i], px[i], py[i], pz[i],\n",
    "                                    a_um=a_um, b_um=b_um,\n",
    "                                    sigma_scale=sigma_scale, S_cap=S_cap)\n",
    "        for i in idx\n",
    "    ], float)\n",
    "    probs = np.clip(probs, 1e-300, 1.0)\n",
    "\n",
    "    # product of K most displaced (smallest probs)\n",
    "    if use_topk and probs.size > use_topk:\n",
    "        kth = np.partition(probs, use_topk-1)[:use_topk]\n",
    "        alpha_hemi = float(np.exp(np.sum(np.log(kth))))\n",
    "    else:\n",
    "        alpha_hemi = float(np.exp(np.sum(np.log(probs))))\n",
    "\n",
    "    return (alpha_hemi < alpha_hemi_cut), alpha_hemi, int(n_good), probs.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "032f85c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_missing_energy(px, py, pz, E, pdg, mask1, mask2,\n",
    "                           sqrt_s=91.2, method=\"simple\", tol=1e-6):\n",
    "    \"\"\"\n",
    "    ALEPH-style missing energy:\n",
    "    - Compute visible hemisphere energies excluding neutrinos\n",
    "    - Compute missing energy as E_true - E_vis.\n",
    "    - Returns also the hemisphere invariant masses (m1^2, m2^2).\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    px,py,pz,E : arrays\n",
    "        Particle kinematics\n",
    "    pdg : array\n",
    "        PDG codes\n",
    "    mask1,mask2 : bool arrays\n",
    "        Hemisphere assignments\n",
    "    sqrt_s : float\n",
    "        CM energy [GeV]\n",
    "    method : {\"simple\",\"aleph\"}\n",
    "        Method for computing E_true\n",
    "    tol : float\n",
    "        Numerical tolerance for negative m^2\n",
    "    \"\"\"\n",
    "\n",
    "    s = sqrt_s**2\n",
    "    E_beam = sqrt_s / 2.0\n",
    "\n",
    "    # --- Visible hemisphere energies (exclude neutrinos)\n",
    "    vis_mask1 = mask1 & np.isin(pdg, list(VISIBLE_PDGS), assume_unique=True)\n",
    "    vis_mask2 = mask2 & np.isin(pdg, list(VISIBLE_PDGS), assume_unique=True)\n",
    "\n",
    "    E_vis1 = np.sum(E[vis_mask1])\n",
    "    E_vis2 = np.sum(E[vis_mask2])\n",
    "\n",
    "    # --- Invariant masses\n",
    "    def m2(px, py, pz, E, mask):\n",
    "        E_h  = E[mask].sum()\n",
    "        px_h = px[mask].sum()\n",
    "        py_h = py[mask].sum()\n",
    "        pz_h = pz[mask].sum()\n",
    "        val = E_h**2 - (px_h**2 + py_h**2 + pz_h**2)\n",
    "        # safeguard: clip only tiny negatives\n",
    "        if val < -tol:\n",
    "            return val  # keep genuine negatives\n",
    "        return max(val, 0.0)\n",
    "\n",
    "    m1_sq = m2(px, py, pz, E, vis_mask1)\n",
    "    m2_sq = m2(px, py, pz, E, vis_mask2)\n",
    "\n",
    "    # --- E_true depending on method\n",
    "    if method == \"simple\":\n",
    "        E_true1 = E_beam\n",
    "        E_true2 = E_beam\n",
    "\n",
    "    elif method == \"aleph\":\n",
    "        E_true1 = (s + m1_sq - m2_sq) / (2 * sqrt_s)\n",
    "        E_true2 = (s + m2_sq - m1_sq) / (2 * sqrt_s)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"method must be 'simple' or 'aleph'\")\n",
    "\n",
    "    # --- Missing energies\n",
    "    E_miss1 = E_true1 - E_vis1\n",
    "    E_miss2 = E_true2 - E_vis2\n",
    "\n",
    "    return (E_vis1, E_miss1, m1_sq), (E_vis2, E_miss2, m2_sq)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d7f2d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------\n",
    "# Main selection function\n",
    "# ------------------------\n",
    "\n",
    "NMAX = 2_000_000\n",
    "\n",
    "def select_missing_energy_events_fast_with_btag(\n",
    "    input_path,\n",
    "    output_events_path,\n",
    "    output_summary_path,\n",
    "    output_allhemis_path=\"all_hemispheres_HEtail.csv\",\n",
    "    sqrt_s=91.2,\n",
    "    min_tracks=7,                 # align with final WP\n",
    "    progress_step=100_000,\n",
    "    energy_method=\"aleph\",\n",
    "    btag_mode=\"aleph\"\n",
    "):\n",
    "\n",
    "    scanned = 0\n",
    "    kept = 0\n",
    "\n",
    "    cut_counts = {\n",
    "        \"total\": 0,\n",
    "        \"thrust_cos\": 0,\n",
    "        \"missing_E\": 0,\n",
    "        \"btag\": 0,\n",
    "        \"opp_veto\": 0,\n",
    "        \"tracks\": 0,\n",
    "        \"lep_veto\": 0,\n",
    "    }\n",
    "\n",
    "    # --- b-tag working point (FINAL) ---\n",
    "    JP_ALPHA_CUT = 0.001     # Jet-Probability CL cut (tight)\n",
    "    B_MIN_TRACKS = 7         # multiplicity on tag hemisphere\n",
    "    B_PMIN       = 0.5       # GeV\n",
    "    B_A_UM       = 25.0\n",
    "    B_B_UM       = 95.0\n",
    "    B_IP_CAP_MM  = 4.0\n",
    "    B_SIG_SCALE  = 1.3978\n",
    "    B_S_CAP      = 5.0\n",
    "\n",
    "    POS_S_MIN    = 3.0       # displaced threshold (positive sign)\n",
    "    POS_S_HARD   = 3.7       # at least one hard positive track\n",
    "\n",
    "    with open(input_path, \"r\") as fin, \\\n",
    "         open(output_events_path, \"w\") as fout_events, \\\n",
    "         open(output_summary_path, \"w\", newline=\"\") as fout_summary, \\\n",
    "         open(output_allhemis_path, \"w\", newline=\"\") as fout_all:  \n",
    "\n",
    "        writer = csv.writer(fout_summary)\n",
    "        writer.writerow([\n",
    "            \"thrust\", \"cos_theta_thrust\",\n",
    "            \"thrust_x\", \"thrust_y\", \"thrust_z\",\n",
    "            \"E_vis_h1\", \"E_miss_h1\", \"tracks_h1\",\n",
    "            \"E_vis_h2\", \"E_miss_h2\", \"tracks_h2\"\n",
    "        ])\n",
    "\n",
    "        writer_all = csv.writer(fout_all)\n",
    "        writer_all.writerow([\"E_miss\", \"hemisphere\", \"event_id\", \"stage\"])\n",
    "\n",
    "        for ev_id, raw in enumerate(fin):\n",
    "            line = raw.strip()\n",
    "            if not line or line.startswith(\"#\"):\n",
    "                continue\n",
    "\n",
    "            tk = line.split()\n",
    "            if len(tk) % 9 != 0:\n",
    "                raise ValueError(f\"Line has {len(tk)} tokens (not multiple of 9).\")\n",
    "\n",
    "            arr = np.fromiter((float(x) for x in tk), dtype=float).reshape(-1, 9)\n",
    "            pdg = arr[:, 0].astype(int)\n",
    "            px, py, pz, E = arr[:, 1:5].T\n",
    "            x_prod, y_prod, z_prod, r_prod = arr[:, 5:9].T\n",
    "\n",
    "            scanned += 1\n",
    "            cut_counts[\"total\"] += 1\n",
    "            if scanned % progress_step == 0:\n",
    "                print(f\"Processed {scanned:,} events... kept {kept:,}\")\n",
    "                \n",
    "            # --- visible mask ---\n",
    "            vis_mask = np.isin(pdg, VISIBLE_PDGS, assume_unique=True)\n",
    "\n",
    "            # --- thrust + cosθ cuts ---\n",
    "            thrust, cos_theta, axis = compute_thrust_with_angle2(px[vis_mask], py[vis_mask], pz[vis_mask])\n",
    "            if thrust <= 0.85 or cos_theta >= 0.7:\n",
    "                continue\n",
    "            cut_counts[\"thrust_cos\"] += 1\n",
    "\n",
    "            # --- hemispheres ---\n",
    "            dot_products = px * axis[0] + py * axis[1] + pz * axis[2]\n",
    "            mask1 = dot_products > 0\n",
    "            mask2 = ~mask1\n",
    "\n",
    "            # --- missing energies ---\n",
    "            (E_vis1, E_miss1, m1_sq), (E_vis2, E_miss2, m2_sq) = compute_missing_energy(\n",
    "                px, py, pz, E, pdg, mask1, mask2, sqrt_s=sqrt_s, method=energy_method\n",
    "            )\n",
    "            E_vis  = [E_vis1, E_vis2]\n",
    "            E_miss = [E_miss1, E_miss2]\n",
    "\n",
    "            # dump after thrust (background spectrum)\n",
    "            writer_all.writerow([E_miss1, 0, ev_id, \"thrust\"])\n",
    "            writer_all.writerow([E_miss2, 1, ev_id, \"thrust\"])\n",
    "\n",
    "            # --- good charged tracks per hemi (E>1 GeV def; for later tracks cut) ---\n",
    "            good_tracks = []\n",
    "            for mask in (mask1, mask2):\n",
    "                E_h = E[mask]\n",
    "                pdg_h = pdg[mask]\n",
    "                track_mask = np.isin(pdg_h, CHARGED_PDGS, assume_unique=True) & (E_h > 1.0)\n",
    "                good_tracks.append(np.count_nonzero(track_mask))\n",
    "\n",
    "            # --- missing-E region cut (HE tail) ---\n",
    "            if not (E_miss[0] > -20 or E_miss[1] > -20):\n",
    "                continue\n",
    "            cut_counts[\"missing_E\"] += 1\n",
    "\n",
    "            # --- choose signal vs opposite hemisphere ---\n",
    "            sig_idx = 0 if E_miss[0] > E_miss[1] else 1\n",
    "            opp_idx = 1 - sig_idx\n",
    "            opp_mask = mask1 if opp_idx == 0 else mask2\n",
    "\n",
    "            # =======================\n",
    "            #        B-TAGGING\n",
    "            # =======================\n",
    "            if btag_mode == \"aleph\":\n",
    "                final_mask = vis_mask & opp_mask  # visible-only tracks in opposite hemi\n",
    "\n",
    "                # get ALL good-track PV probabilities (no decision inside helper)\n",
    "                is_raw, alpha_raw, n_good_btag, track_probs = hemisphere_btag_aleph_simple(\n",
    "                    x_mm=x_prod[final_mask], y_mm=y_prod[final_mask],\n",
    "                    px=px[final_mask],     py=py[final_mask],     pz=pz[final_mask],\n",
    "                    pdg=pdg[final_mask],\n",
    "                    alpha_hemi_cut=1.0,          # return probs only\n",
    "                    min_tracks=B_MIN_TRACKS, pmin=B_PMIN,\n",
    "                    a_um=B_A_UM, b_um=B_B_UM, ip_cap_mm=B_IP_CAP_MM,\n",
    "                    sigma_scale=B_SIG_SCALE, S_cap=B_S_CAP, use_topk=0\n",
    "                )\n",
    "                if n_good_btag < B_MIN_TRACKS:\n",
    "                    continue\n",
    "\n",
    "                # (A) Jet-Probability CL over ALL good tracks\n",
    "                probs = np.clip(np.asarray(track_probs, float), 1e-300, 1.0)\n",
    "                alpha_all = float(np.exp(np.sum(np.log(probs))))\n",
    "                T = -np.log(alpha_all)\n",
    "                jp_sum, term = 1.0, 1.0\n",
    "                for j in range(1, n_good_btag):\n",
    "                    term *= T / j\n",
    "                    jp_sum += term\n",
    "                jp_cl = alpha_all * jp_sum\n",
    "                if jp_cl >= JP_ALPHA_CUT:\n",
    "                    continue\n",
    "\n",
    "                # (B) Topology: ≥2 positive displaced (|S|>3.0) AND ≥1 hard hit (|S|>3.7)\n",
    "                px_o = px[final_mask]; py_o = py[final_mask]\n",
    "                x_o  = x_prod[final_mask]; y_o = y_prod[final_mask]\n",
    "                pT   = np.hypot(px_o, py_o)\n",
    "                vx   = np.divide(px_o, pT, out=np.zeros_like(px_o), where=pT>1e-12)\n",
    "                vy   = np.divide(py_o, pT, out=np.zeros_like(py_o), where=pT>1e-12)\n",
    "                d0_mm = np.abs(x_o*vy - y_o*vx)\n",
    "\n",
    "                p3 = np.sqrt(px_o**2 + py_o**2 + pz[final_mask]**2) + 1e-12\n",
    "                sigma_um = np.sqrt((B_A_UM * B_SIG_SCALE)**2 + (B_B_UM * B_SIG_SCALE / p3)**2)\n",
    "                S_abs = np.minimum(1e3 * d0_mm / np.maximum(sigma_um, 1e-3), B_S_CAP)  # mm→μm, cap\n",
    "\n",
    "                sgn = np.sign(x_o*py_o - y_o*px_o) * np.sign(axis[2])\n",
    "                pos_disp = (sgn > 0) & (S_abs > POS_S_MIN)\n",
    "                hard_hit = (sgn > 0) & (S_abs > POS_S_HARD)\n",
    "                if (np.count_nonzero(pos_disp) < 2) or (not np.any(hard_hit)):\n",
    "                    continue\n",
    "\n",
    "                cut_counts[\"btag\"] += 1\n",
    "            # =======================\n",
    "\n",
    "            # --- opposite hemisphere veto (align to 20 GeV) ---\n",
    "            if E_miss[opp_idx] >= 20:\n",
    "                continue\n",
    "            cut_counts[\"opp_veto\"] += 1\n",
    "\n",
    "            # --- tracks cut (your E>1 GeV good-track count) ---\n",
    "            if good_tracks[opp_idx] < min_tracks:\n",
    "                continue\n",
    "            cut_counts[\"tracks\"] += 1\n",
    "\n",
    "            # --- semileptonic veto on the signal hemisphere ---\n",
    "            sig_mask = mask1 if sig_idx == 0 else mask2\n",
    "            if has_identified_lepton(\n",
    "                pdg[sig_mask],\n",
    "                E[sig_mask],\n",
    "                np.sqrt(px[sig_mask]**2 + py[sig_mask]**2 + pz[sig_mask]**2)\n",
    "            ):\n",
    "                continue\n",
    "            cut_counts[\"lep_veto\"] += 1\n",
    "\n",
    "            # --- store selected event ---\n",
    "            fout_events.write(line + \"\\n\")\n",
    "            writer.writerow([\n",
    "                thrust, cos_theta,\n",
    "                axis[0], axis[1], axis[2],\n",
    "                E_vis[0], E_miss[0], good_tracks[0],\n",
    "                E_vis[1], E_miss[1], good_tracks[1]\n",
    "            ])\n",
    "            kept += 1     \n",
    "\n",
    "    # --- cutflow summary ---\n",
    "    print(\"\\n--- Cutflow summary ---\")\n",
    "    for step, n in cut_counts.items():\n",
    "        frac = 100.0 * n / cut_counts[\"total\"] if cut_counts[\"total\"] > 0 else 0.0\n",
    "        print(f\"{step:12s}: {n:,}  ({frac:.6f}%)\")\n",
    "\n",
    "    print(f\"\\nFinal kept events: {kept:,} ({100*kept/cut_counts['total']:.6f}%)\")\n",
    "    return cut_counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbdd1880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 100,000 events... kept 0\n",
      "Processed 200,000 events... kept 1\n",
      "Processed 300,000 events... kept 1\n",
      "Processed 400,000 events... kept 1\n",
      "Processed 500,000 events... kept 1\n",
      "Processed 600,000 events... kept 2\n",
      "Processed 700,000 events... kept 2\n",
      "Processed 800,000 events... kept 2\n",
      "Processed 900,000 events... kept 2\n",
      "Processed 1,200,000 events... kept 3\n",
      "Processed 1,300,000 events... kept 3\n",
      "Processed 1,400,000 events... kept 3\n",
      "Processed 1,500,000 events... kept 4\n",
      "Processed 1,600,000 events... kept 5\n",
      "Processed 1,700,000 events... kept 6\n",
      "Processed 1,800,000 events... kept 6\n",
      "Processed 1,900,000 events... kept 7\n",
      "Processed 2,000,000 events... kept 8\n",
      "Processed 2,100,000 events... kept 9\n",
      "Processed 2,200,000 events... kept 9\n",
      "Processed 2,300,000 events... kept 9\n",
      "Processed 2,400,000 events... kept 9\n",
      "Processed 2,500,000 events... kept 9\n",
      "Processed 2,600,000 events... kept 9\n",
      "Processed 2,700,000 events... kept 9\n",
      "Processed 2,800,000 events... kept 9\n",
      "Processed 2,900,000 events... kept 9\n",
      "Processed 3,000,000 events... kept 9\n",
      "Processed 3,100,000 events... kept 9\n",
      "Processed 3,200,000 events... kept 9\n",
      "Processed 3,300,000 events... kept 9\n",
      "Processed 3,400,000 events... kept 9\n",
      "Processed 3,500,000 events... kept 9\n",
      "Processed 3,600,000 events... kept 10\n",
      "Processed 3,700,000 events... kept 11\n",
      "Processed 4,100,000 events... kept 12\n",
      "\n",
      "--- Cutflow summary ---\n",
      "total       : 4,176,778  (100.000000%)\n",
      "thrust_cos  : 2,286,715  (54.748301%)\n",
      "missing_E   : 212  (0.005076%)\n",
      "btag        : 38  (0.000910%)\n",
      "opp_veto    : 38  (0.000910%)\n",
      "tracks      : 24  (0.000575%)\n",
      "lep_veto    : 12  (0.000287%)\n",
      "\n",
      "Final kept events: 12 (0.000287%)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'total': 4176778,\n",
       " 'thrust_cos': 2286715,\n",
       " 'missing_E': 212,\n",
       " 'btag': 38,\n",
       " 'opp_veto': 38,\n",
       " 'tracks': 24,\n",
       " 'lep_veto': 12}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = \"selected_hadronic_smeared.txt\"\n",
    "\n",
    "# ALEPH-style missing energy + ALEPH-style b-tag\n",
    "select_missing_energy_events_fast_with_btag(\n",
    "    filename, \"selected_aleph_HEtail.txt\", \"summary_alephHE_tail.csv\",\n",
    "    energy_method=\"aleph\",\n",
    "    btag_mode=\"aleph\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2e4b2a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 100,000 events... kept 3,561\n",
      "Processed 200,000 events... kept 7,169\n",
      "Processed 300,000 events... kept 10,759\n",
      "Processed 400,000 events... kept 14,447\n",
      "Processed 500,000 events... kept 17,913\n",
      "Processed 600,000 events... kept 21,467\n",
      "Processed 700,000 events... kept 25,129\n",
      "Processed 800,000 events... kept 28,669\n",
      "Processed 900,000 events... kept 32,130\n",
      "Processed 1,000,000 events... kept 35,685\n",
      "Processed 1,100,000 events... kept 39,221\n",
      "Processed 1,200,000 events... kept 42,823\n",
      "Processed 1,300,000 events... kept 46,378\n",
      "Processed 1,400,000 events... kept 49,834\n",
      "Processed 1,500,000 events... kept 53,360\n",
      "Processed 1,600,000 events... kept 56,951\n",
      "Processed 1,700,000 events... kept 60,442\n",
      "Processed 1,800,000 events... kept 64,001\n",
      "Processed 1,900,000 events... kept 67,556\n",
      "Processed 2,000,000 events... kept 71,070\n",
      "Processed 2,100,000 events... kept 74,660\n",
      "Processed 2,200,000 events... kept 78,195\n",
      "Processed 2,300,000 events... kept 81,724\n",
      "Processed 2,400,000 events... kept 85,323\n",
      "Processed 2,500,000 events... kept 88,904\n",
      "Processed 2,600,000 events... kept 92,532\n",
      "Processed 2,700,000 events... kept 96,186\n",
      "Processed 2,800,000 events... kept 99,651\n",
      "Processed 2,900,000 events... kept 103,226\n",
      "Processed 3,000,000 events... kept 106,747\n",
      "Processed 3,100,000 events... kept 110,369\n",
      "Processed 3,200,000 events... kept 113,856\n",
      "Processed 3,300,000 events... kept 117,388\n",
      "Processed 3,400,000 events... kept 121,022\n",
      "Processed 3,500,000 events... kept 124,669\n",
      "Processed 3,600,000 events... kept 128,188\n",
      "Processed 3,700,000 events... kept 131,761\n",
      "Processed 3,800,000 events... kept 135,273\n",
      "Processed 3,900,000 events... kept 138,858\n",
      "Processed 4,000,000 events... kept 142,310\n",
      "Processed 4,100,000 events... kept 145,938\n",
      "\n",
      "--- Cutflow summary ---\n",
      "total       : 4,176,778  (100.000000%)\n",
      "thrust_cos  : 2,286,715  (54.748301%)\n",
      "missing_E   : 2,286,715  (54.748301%)\n",
      "btag        : 330,575  (7.914593%)\n",
      "opp_veto    : 330,541  (7.913779%)\n",
      "tracks      : 234,662  (5.618254%)\n",
      "lep_veto    : 148,697  (3.560089%)\n",
      "\n",
      "Final kept events: 148,697 (3.560089%)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'total': 4176778,\n",
       " 'thrust_cos': 2286715,\n",
       " 'missing_E': 2286715,\n",
       " 'btag': 330575,\n",
       " 'opp_veto': 330541,\n",
       " 'tracks': 234662,\n",
       " 'lep_veto': 148697}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = \"selected_hadronic_smeared.txt\"\n",
    "\n",
    "# Simple half-beam energy + simple displacement b-tag\n",
    "select_missing_energy_events_fast_with_btag(\n",
    "    filename, \"selected_aleph_all.txt\", \"summary_aleph_all.csv\",\n",
    "    energy_method=\"aleph\",\n",
    "     btag_mode=\"aleph\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f737f96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
